# Ness DataFog - Aplica√ß√£o de Prote√ß√£o de Dados

Uma aplica√ß√£o web moderna em portugu√™s para processamento e detec√ß√£o de dados sens√≠veis em documentos brasileiros, desenvolvida pela Ness.

## Funcionalidades

### üîí Detec√ß√£o de Dados Sens√≠veis
- **Documentos Brasileiros**: CPF, CNPJ, RG, Telefone, CEP
- **Dados Financeiros**: Contas banc√°rias, cart√µes de cr√©dito, PIX
- **Documentos Pessoais**: CNH, T√≠tulo de eleitor, Cart√£o SUS
- **Regex Personalizados**: Padr√µes customiz√°veis para necessidades espec√≠ficas

### üìÅ Upload e Processamento
- **Interface Web**: Upload via drag-and-drop
- **SFTP**: Monitoramento autom√°tico de diret√≥rio
- **Formatos Suportados**: PDF, DOC/DOCX, TXT, ZIP, CSV
- **Processamento em Lote**: Extra√ß√£o e an√°lise de arquivos ZIP

### üìä Dashboard em Tempo Real
- **Status de Processamento**: Acompanhamento em tempo real
- **Estat√≠sticas**: Distribui√ß√£o por n√≠vel de risco
- **Visualiza√ß√£o**: Detec√ß√µes por tipo de documento
- **Progresso**: Barras de progresso para cada arquivo

### üìà Relat√≥rios e Exporta√ß√£o
- **Formato JSON**: Relat√≥rios estruturados
- **Formato CSV**: Compat√≠vel com Excel
- **Filtros**: Por arquivo, tipo de dados, n√≠vel de risco
- **Hist√≥rico**: Controle de processamentos anteriores

## Tecnologias

### Frontend
- **React + TypeScript**: Interface moderna e tipada
- **Tailwind CSS**: Design system responsivo
- **Shadcn/UI**: Componentes acess√≠veis
- **TanStack Query**: Gerenciamento de estado e cache
- **Wouter**: Roteamento leve

### Backend
- **Node.js + Express**: API RESTful
- **TypeScript**: Tipagem est√°tica
- **PostgreSQL**: Banco de dados relacional
- **Drizzle ORM**: Type-safe database queries
- **Multer**: Upload de arquivos

### Processamento
- **DataFog Python**: Engine de detec√ß√£o
- **Regex Brasileiros**: Padr√µes otimizados
- **ZIP Extraction**: Processamento de arquivos compactados
- **SFTP Monitor**: Monitoramento autom√°tico

## Instala√ß√£o

### Pr√©-requisitos
```bash
# Node.js 20+
curl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash -
sudo apt-get install -y nodejs

# Python 3.11+
sudo apt-get install python3.11 python3.11-pip

# PostgreSQL
sudo apt-get install postgresql postgresql-contrib
```

### Configura√ß√£o do Projeto
```bash
# Clone o reposit√≥rio
git clone <repository-url>
cd ness-datafog

# Instale depend√™ncias
npm install

# Configure vari√°veis de ambiente
cp .env.example .env

# Configure o banco de dados
npm run db:push

# Inicie o servidor
npm run dev
```

### Configura√ß√£o SFTP (Opcional)
```bash
# Criar estrutura de diret√≥rios
sudo mkdir -p /home/datafog/uploads/sftp/{incoming,processing,processed}
sudo mkdir -p /home/datafog/exports/{csv,json}

# Configurar usu√°rio SFTP
sudo useradd -m -s /bin/bash datafog-sftp
sudo chown -R datafog-sftp:datafog-sftp /home/datafog/

# Ver SFTP_SETUP.md para configura√ß√£o completa
```

## Uso

### Upload via Interface Web
1. Acesse a aplica√ß√£o
2. Selecione "Upload de Arquivos"
3. Arraste arquivos ou clique para selecionar
4. Configure padr√µes de detec√ß√£o
5. Clique em "Iniciar Processamento"

### Upload via SFTP
1. Configure credenciais SFTP
2. Envie arquivos ZIP para `/uploads/sftp/incoming/`
3. O sistema processa automaticamente
4. Resultados dispon√≠veis no dashboard

### Visualiza√ß√£o de Resultados
1. Acesse "Buscar Dados" ou "Dashboard"
2. Visualize detec√ß√µes por n√≠vel de risco
3. Filtre por tipo de documento
4. Exporte relat√≥rios em JSON/CSV

## Padr√µes de Detec√ß√£o

### Documentos Pessoais
- **CPF**: Formato XXX.XXX.XXX-XX ou 11 d√≠gitos
- **CNPJ**: Formato XX.XXX.XXX/XXXX-XX ou 14 d√≠gitos
- **RG**: Diversos formatos estaduais
- **Telefone**: Celular e fixo brasileiro

### Documentos Financeiros
- **Conta Banc√°ria**: N√∫meros de conta
- **Ag√™ncia Banc√°ria**: C√≥digos de ag√™ncia
- **Cart√£o de Cr√©dito**: 16 d√≠gitos formatados

### Documentos Governamentais
- **CNH**: Carteira Nacional de Habilita√ß√£o
- **T√≠tulo de Eleitor**: 12 d√≠gitos
- **Cart√£o SUS**: 15 d√≠gitos
- **PIS/PASEP**: Formato XXX.XXXXX.XX-X

## API Endpoints

### Upload
- `POST /api/files/upload` - Upload de arquivos
- `GET /api/files` - Listar arquivos

### Processamento
- `POST /api/processing/start` - Iniciar processamento
- `GET /api/processing/jobs` - Status dos jobs
- `GET /api/processing/stats` - Estat√≠sticas

### Resultados
- `GET /api/detections` - Listar detec√ß√µes
- `GET /api/reports/export` - Exportar JSON
- `GET /api/reports/export/csv` - Exportar CSV

## Configura√ß√£o de Desenvolvimento

### Estrutura do Projeto
```
‚îú‚îÄ‚îÄ client/           # Frontend React
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pages/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ lib/
‚îú‚îÄ‚îÄ server/           # Backend Node.js
‚îÇ   ‚îú‚îÄ‚îÄ routes.ts
‚îÇ   ‚îú‚îÄ‚îÄ storage.ts
‚îÇ   ‚îî‚îÄ‚îÄ datafog-processor.ts
‚îú‚îÄ‚îÄ shared/           # Tipos compartilhados
‚îÇ   ‚îî‚îÄ‚îÄ schema.ts
‚îî‚îÄ‚îÄ docs/            # Documenta√ß√£o
```

### Scripts Dispon√≠veis
```bash
npm run dev          # Servidor de desenvolvimento
npm run build        # Build de produ√ß√£o
npm run db:push      # Atualizar schema do banco
npm run lint         # Verificar c√≥digo
npm run test         # Executar testes
```

## Seguran√ßa

### Prote√ß√£o de Dados
- Criptografia de dados sens√≠veis
- Logs de auditoria
- Acesso controlado via SFTP
- Isolamento de processos

### Compliance
- LGPD - Lei Geral de Prote√ß√£o de Dados
- Anonimiza√ß√£o de dados sens√≠veis
- Relat√≥rios de conformidade
- Controle de reten√ß√£o

## Suporte

### Logs
- Aplica√ß√£o: Console do browser
- Servidor: `npm run dev` logs
- SFTP: `/var/log/datafog/`
- Processamento: Logs em tempo real

### Troubleshooting
1. Verifique logs do servidor
2. Confirme configura√ß√£o do banco
3. Valide permiss√µes SFTP
4. Teste conectividade Python

## Contribui√ß√£o

### Padr√µes de C√≥digo
- TypeScript estrito
- ESLint + Prettier
- Commits sem√¢nticos
- Testes unit√°rios

### Workflow
1. Fork do reposit√≥rio
2. Branch para feature
3. Implementa√ß√£o + testes
4. Pull request com descri√ß√£o

---

Desenvolvido com ‚ù§Ô∏è pela **Ness** para prote√ß√£o de dados brasileiros.